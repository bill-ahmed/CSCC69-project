       	     +-------------------------+
             | CSCC69                  |
             | PROJECT 4: FILE SYSTEMS |
             | DESIGN DOCUMENT         |
             +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Bilal Ahmed bill.ahmed@mail.utoronto.ca
Tanner Bergeron tanner.bergeron@mail.utoronto.ca

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

             INDEXED AND EXTENSIBLE FILES
             ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* In inode.h */
/* List of sectors in the fs being written to atm */
struct list sectors_in_use = LIST_INITIALIZER(sectors_in_use);

/* Used to keep track of which sector is being written
to in the file system block sectors_in_use list */
struct sector_lock
{
    block_sector_t sector;
    struct list_elem elem;
};

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

    Our inode stores in an array:
    (1) 10 direct block sector indexes
        - 10 * 512 bytes = 5KB (data)
    (2) 1 indirect block sector index
        - Each indirect block stores the indexes of 128 direct blocks
        - 1 * 128 * 512 bytes = 64KB (data)
        - With the one indirect block 512 bytes as overhead.
    (3) 1 double indirect block sector index.
        - The double indirect block points to 128 indirect blocks
        - Each of those indirect blocks points to 128 direct blocks
        - Each direct block stores 512 bytes of data.
        - 1 * 128 * 128 * 512 bytes = 8MB (data)
        - There are 128 indirect + 1 double indirect blocks (64.5KB) as overhead.

    In total this means that a single file can store: 
    8096 + 64 + 5 = 8165KB of data
    while requiring 8165 + 64.5 + 0.5 = 8230KB total disk space to store that data.

    This means that in our file system, assuming it is capped at 8MB, a single
    file in pintos will never become absolutely full.

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

    Each time there is a write that would extend the length of a file,
    we break up the write into one block at a time. This way no one
    file can hog the resources or allocate itself the entire disk
    blocking out other processes also trying to write data to the disk. 

    The problem of two processes trying to extend their files at the
    same time becomes straight forward to handle once what is explained
    above is implemented. Since each user write is handled one block at
    a time, if thread A needs to write to many many sectors, and at the
    same time thread B only needs to write to one, then at the time
    thread B is executing, it won't be blocked from grabbing a block to
    write to, even if A is in the middle of trying to write many blocks
    during it's write syscall.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

    There are two cases that would happen with our code, which depends
    on which process is executing at the time of thier intended operation.

    If A gets there first and sees no lock on that block, then it will 
    read, see the EOF, and return having read "nothing". Then process B 
    will be free to write and aquire the modification lock. The modification
    lock will only stop other processes from *starting* a read/write, but
    won't stop a reader from reading if it was already doing so at the time
    another process aquires the modification lock. So if A starts a read
    and then is interupted, and B aquires the lock and writes to that block.
    Remember that the modification lock is per block so that the write call
    doesn't gate other processes from reading entirely.
    
    If B gets there first and intends to write, it sets a lock on that
    block and writes whatever data to that block and unlocks it 
    afterwards. Like above, the other reading processes can read it
    still as they would normally be able to do.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

    Is it fair because only one block per process is ever locked down for
    modification at one time. This allows other readers to still have full
    access to read from other areas of the file during a write.

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

    The inode structure we use is 10 direct block pointers, 1 indirect block
    pointer, and 1 double-indirect block pointer. We feel this gives a good
    balance between speedy access to smaller files (<5KB) while still supporting
    file sizes up to about 8MB (plus whatever overhead is involved with storing
    indirect blocks) by having access to one double-indirect block.

                SUBDIRECTORIES
                ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

                 BUFFER CACHE
                 ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* This is our buffer cache */
struct list buffer_cache;

/* This is the actual data associated to a buffer block */
struct buffer_elem
{
    struct list_elem elem;
    data_buffer[BLOCK_SECTOR_SIZE];
    block_sector_t sector;
    bool marked;
};

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

    We append buffer elems to the end of the list when we would like to add
    a new buffer elem to our cache. 
    
    When chosing to evict, we go through the list starting from the front and
    at each element, if it is not marked, we mark it for eviction and keep going,
    but if we come across an elem already marked for eviction, we evict that one
    (write to disk) and return. 
    
    Each read or write to a buffer unmarks an elem for eviction because it is
    likely to be used again if it is used once.

    This is our version of the second chance algorithm. 

>> C3: Describe your implementation of write-behind.

    The operating system spawns a thread at the beginning of startup that sleeps 
    for 5 seconds and then runs the backup function which writes the contents of
    the cache to the disk. This loops until the thread is terminated at shutdown.

    As well on each eviction of the cache, that evicted sector is written to the
    disk. This avoids doing a write each time and dirty copy available for fast
    access.

>> C4: Describe your implementation of read-ahead.

    Whenever there is a call read a sector, if the next sector of that
    file is not already in the cache, we spawn a thread to read in that next 
    sector of the file and put it in the cache, so that the next read which
    likely will want the next sector of the file will be able to grab it from
    the cache instead.
    
    Since we deligate this read to a new thread, the thread that called the block_read
    will not be slowed down by also reading the sector infront of it as well. The thread
    then exits after. The function passed into this thread is able to be told the number
    of sectors in the file to read ahead so this is able to be tuned to figure out a
    good number for performance. By default and recommended in the handout, it is 1.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

    The same list of sector locks used for currently being accessed sectors
    is also used here. If a thread wants to write to or evict that sector, it
    must aquire the sector lock for that sector. This also stops new readers
    but not readers currently reading the sector. Therefore if a thread attempts
    to modify the contents of that block, it will have to wait until the thread
    currently modifying it finishes. This avoids any cases where something is
    being written to and trying to be evicted at the same time and visa versa.  

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

    Similar to (C5), attempting to evict requires grabbing the sector lock
    and no reads or writes will be allowed to that block until the lock is
    released. This prevents accidental overwrites or missing data or reading
    garbage data.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

    A workload to benefit from buffer caching is one where there are
    a few files small files being accessed very frequently. For example
    making immediate backups of large intermediate calculations like
    with needing to save large numbers and or strings frequently modified.

    Workloads to benefit from read-ahead write-behind are ones where
    long sequential read/writes are performed on files. Like for instance
    reading or writing a large book somewhere in disk. 

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
